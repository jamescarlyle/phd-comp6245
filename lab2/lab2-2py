import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import RidgeCV , LassoCV
from sklearn.metrics import mean_squared_error


# Load data from URL.
df = pd . read_csv ("https://raw.githubusercontent.com/selva86/datasets/master/Hitters.csv")

# Drop rows with missing ‘Salary‘ values.
df = df.dropna(subset =["Salary"])
# Perform one-hot encoding on categorical features.
X = pd.get_dummies(df.drop("Salary", axis =1), drop_first = True)
y = df["Salary"]

# Split data.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state =42)

# Scale features.
scaler = StandardScaler ()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Use ‘RidgeCV‘ to find the best ‘alpha‘ for the Ridge model from a predefined list.
# Define a range of alphas.
alphas = np.logspace(-2, 4, 100)

# Find the best alpha using cross - validation.
ridge_cv = RidgeCV ( alphas = alphas , store_cv_values = True )
ridge_cv . fit ( X_train_scaled , y_train )

print ( f" Best alpha for Ridge : { ridge_cv . alpha_ :.4f}")
# Use ‘LassoCV‘ to find the best ‘alpha‘ for the Lasso model.
lasso_cv = LassoCV ( alphas = alphas , cv =5 , random_state =42 , max_iter =10000)
lasso_cv . fit ( X_train_scaled , y_train )

# Evaluate both final models on the unseen test set using Mean Squared Error (MSE).
# Make predictions on the test set
ridge_pred = ridge_cv.predict ( X_test_scaled )
lasso_pred = lasso_cv.predict ( X_test_scaled )

# Calculate and print test MSE
print ( f" Ridge Test MSE: { mean_squared_error (y_test , ridge_pred ):.2f}")
print ( f" Lasso Test MSE: { mean_squared_error (y_test , lasso_pred ):.2f}")

print ( f" Best alpha for Lasso : { lasso_cv.alpha_ :.4f}")
print (ridge_cv.coef_)
print (lasso_cv.coef_)

# Get the indices of the most important 8 features in descending order (i.e. most important feature first).
ridge_important_features = np.argsort(np.abs(ridge_cv.coef_))[::-1][:8]
lasso_important_features = np.argsort(np.abs(lasso_cv.coef_))[::-1][:8]

# Calculate the most important coefficients for Ridge and Lasso.
ridge_important_values = np.take(ridge_cv.coef_, ridge_important_features)
ridge_important_col_names = np.take(df.columns, ridge_important_features)
lasso_important_values = np.take(lasso_cv.coef_, lasso_important_features)
lasso_important_col_names = np.take(df.columns, lasso_important_features)

# Plot the most important coefficient names and their values.
plt.bar(ridge_important_col_names, ridge_important_values)
plt.xlabel('Feature')
plt.ylabel('Absolute Coefficient')
plt.title('Feature Importance by Absolute Coefficient for Ridge')
plt.show()

plt.bar(lasso_important_col_names, lasso_important_values)
plt.xlabel('Feature')
plt.ylabel('Absolute Coefficient')
plt.title('Feature Importance by Absolute Coefficient for Lasso')
plt.show()